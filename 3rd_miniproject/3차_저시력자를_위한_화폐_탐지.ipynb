{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **저시력자를 위한 원화 화폐 분류**\n","---\n","- 본 과제는 UltraLytics YOLO v5 모델 사용을 권장합니다.\n","    - 본 파일의 목차는 UltraLytics YOLO v5에 맞게 작성되어 있습니다.\n","    - 다른 모델을 찾아서 사용하셔도 좋습니다.\n","    - 산출물이 잘 나오면 됩니다 : )\n","---"],"metadata":{"id":"XT7PRhnMf-kI"}},{"cell_type":"markdown","source":["## 0.미션\n","---\n","- **과제 수행 목표**\n","    - 본 과제는 Object Detection 문제입니다.\n","    - Object Detection 문제로 접근하기 위해 **데이터셋 전처리**를 하셔야 합니다.\n","    - 데이터셋 : money_dataset.zip\n","        1. 데이터셋은 압축 파일로 제공됩니다.\n","        2. 압축 파일 안에는 화폐마다 폴더가 개별적으로 존재합니다.\n","        3. 폴더 안에는 화폐 이미지와 화폐 정보가 담긴 json 파일이 있습니다.\n","    - 여러분이 직접 촬영한 화폐 사진들을 탐지 과정에서 이용 해보세요.\n","    - 이미지에 화폐 하나만 나오게 촬영하는 것은 지양해주세요.\n","    - 다양한 방법으로 화폐를 촬영하고 결과를 확인해보세요.\n","        - ex 1) 화폐의 모든 종류를 한 이미지에 나오게 촬영\n","        - ex 2) 여러 화폐를 겹치게 하여 촬영\n","---\n","- **Key Point**\n","    1. 모델에 맞는 폴더 구조 확인\n","    2. 이미지 축소 비율에 맞춰 좌표값 변경\n","        - 좌표를 이미지 리사이즈한 비율로 변경\n","    3. 모델에 맞는 정보 추출/형식 변경\n","        - json 파일에서 정보 추출 및 모델 형식에 맞게 변경\n","    4. 화폐당 하나의 클래스로 변경\n","        - 총 8개 클래스\n","    5. 모델 선택 필요\n","---"],"metadata":{"id":"47D2vGDYdCOz"}},{"cell_type":"markdown","source":["## 1.환경설정"],"metadata":{"id":"aZon1K-Ag9be"}},{"cell_type":"markdown","source":["### (1) 구글 드라이브 연동, 데이터 다운로드\n","---\n","- 아래의 코드 셀을 반드시 실행시켜야 합니다.\n","---"],"metadata":{"id":"CMgnHN9ZBF05"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"id":"xCplyiojBFwh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695565244794,"user_tz":-540,"elapsed":50400,"user":{"displayName":"현수","userId":"15599720930867665035"}},"outputId":"0a39216a-be39-488c-c6bf-6ff8012e78bd"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["# !pip install gdown"],"metadata":{"id":"5sUNGwmDxAda","executionInfo":{"status":"ok","timestamp":1695565244795,"user_tz":-540,"elapsed":8,"user":{"displayName":"현수","userId":"15599720930867665035"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["### (2) 데이터셋 불러오기\n","---\n","- **세부요구사항**\n","    - 데이터셋 파일의 압축을 해제하세요.\n","---\n","- 예제 코드에서는 zipfile 모듈을 이용하였습니다.\n","    - [zipfile document](https://docs.python.org/3/library/zipfile.html#zipfile-objects)\n","    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","---"],"metadata":{"id":"J8vjv0acBAV4"}},{"cell_type":"code","source":["import zipfile, gdown\n","from tqdm import tqdm\n","from pathlib import Path,os\n","base_path = Path('/content/drive/MyDrive/에이블/미니프로젝트3차')\n","data_path = base_path / Path('dataset')\n","raw_path = base_path/Path('raw')\n","file_name = Path(\"money_dataset.zip\")\n","money_data_path = base_path / file_name"],"metadata":{"id":"Xoh4IyAWc4kT","executionInfo":{"status":"ok","timestamp":1695565244795,"user_tz":-540,"elapsed":6,"user":{"displayName":"현수","userId":"15599720930867665035"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"bkSa5ejf8LMe","executionInfo":{"status":"ok","timestamp":1695565244795,"user_tz":-540,"elapsed":5,"user":{"displayName":"현수","userId":"15599720930867665035"}}},"outputs":[],"source":["# import zipfile, gdown,os\n","# url =\"https://drive.google.com/file/d/1k1tXDK35s6BsMTPGWSl5GVGNoPfC898X/view?usp=drive_link\"\n","# file_name = \"money_dataset.zip\"\n","# output = \"/content/drive/MyDrive/에이블/미니프로젝트3차/\" + file_name # 변경 가능\n","# if not os.path.exists(output):\n","#     gdown.download(url=url, output=output, quiet=False, fuzzy=True)"]},{"cell_type":"code","source":["# 데이터셋 압축 파일 경로 : 유저별로 상이할 수 있음\n","money_data = zipfile.ZipFile(money_data_path)"],"metadata":{"id":"N4cdpkRv86QQ","executionInfo":{"status":"ok","timestamp":1695565246338,"user_tz":-540,"elapsed":1548,"user":{"displayName":"현수","userId":"15599720930867665035"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TW4uDVGOJnZ7","executionInfo":{"status":"ok","timestamp":1695565248642,"user_tz":-540,"elapsed":2309,"user":{"displayName":"현수","userId":"15599720930867665035"}},"outputId":"6c2efe73-b260-4c43-d928-ea52ddce50de"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# 데이터셋 압축 해제\n","money_data.extractall('/content/Dataset/')"],"metadata":{"id":"TDAyDRLT9hZS","executionInfo":{"status":"ok","timestamp":1695565261345,"user_tz":-540,"elapsed":12707,"user":{"displayName":"현수","userId":"15599720930867665035"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## 2.데이터 전처리"],"metadata":{"id":"QyEd-WNIhoSc"}},{"cell_type":"markdown","source":["### (1) 폴더 구조 생성 및 파일 이동\n","---\n","- **세부요구사항**\n","    -  모델에서 요구하는 폴더 구조를 만들어야 합니다.\n","        - Hint : Image와 Label을 구분하는 폴더를 만들어 주세요\n","---\n","- 예제 코드에서는 glob, shutil 모듈을 이용하였습니다.\n","    - [glob document](https://docs.python.org/3/library/glob.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n","    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","---"],"metadata":{"id":"P81d6utx-3LY"}},{"cell_type":"code","source":["# 1.폴더 구조 만들기\n","!mkdir /content/Dataset/images;\n","!mkdir /content/Dataset/images/train; mkdir /content/Dataset/images/val\n","\n","!mkdir /content/Dataset/labels;\n","!mkdir /content/Dataset/labels/train; mkdir /content/Dataset/labels/val"],"metadata":{"id":"YBqCJU5z_UI8","executionInfo":{"status":"ok","timestamp":1695565299470,"user_tz":-540,"elapsed":753,"user":{"displayName":"현수","userId":"15599720930867665035"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import glob, shutil"],"metadata":{"id":"UuchlNA_DftJ","executionInfo":{"status":"ok","timestamp":1695565299471,"user_tz":-540,"elapsed":3,"user":{"displayName":"현수","userId":"15599720930867665035"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# 2. Dataset metadata 입력\n","won_list = ['10', '50', '100', '500', '1000', '5000', '10000', '50000']\n","data_path = '/content/Dataset/'"],"metadata":{"id":"Q3lnYcLS_UOy","executionInfo":{"status":"ok","timestamp":1695565299871,"user_tz":-540,"elapsed":3,"user":{"displayName":"현수","userId":"15599720930867665035"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["---\n","- 데이터를 Training set | Validation set으로 분할하세요.\n","    - 예시 : Training과 Validation은 8:2로 분리\n","- Hint : 이미지 데이터는 /images에, JSON 데이터는 /labels에 넣어주세요\n","    - 예시 : /dataset/images/train, /dataset/labels/train\n","    - 예제 코드에서는 glob, shutil 모듈을 이용하였습니다.\n","    - [glob document](https://docs.python.org/3/library/glob.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n","\n","    ※ 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","    \n","---"],"metadata":{"id":"ihJgeqXJG1Ml"}},{"cell_type":"code","source":["# jpg, json 파일 분리를 위한 함수 생성\n","def moving(data):\n","    for cur in glob.glob(f'/content/Dataset/{data}/*.jpg'):\n","        shutil.copy(cur, '/content/Dataset/images/train')\n","    for cur in glob.glob(f'/content/Dataset/{data}/*.json'):\n","        shutil.copy(cur, '/content/Dataset/labels/train')\n","\n","# 단위별로 개별 폴더에 있는 파일을 하나하나 들어가 빼내주기 위한 반복문\n","money=10\n","while(money<=10000):\n","    moving(money)\n","    money*=10\n","money=50\n","while(money<=50000):\n","    moving(money)\n","    money*=10\n","\n","# jpg와 json을 나눠서 각각 train데이터에 넣었음"],"metadata":{"id":"CIBCsCBlyV3c","executionInfo":{"status":"ok","timestamp":1695565304219,"user_tz":-540,"elapsed":1576,"user":{"displayName":"현수","userId":"15599720930867665035"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# images-train과 labels-train에 있는 0.2퍼를 images-val과 labels-var로 보냄\n","# 그럼 images-train이랑 labels-train에는 0.8퍼만 남아있도록 파일 이동\n","# 3. 데이터를 Training set | Validation set으로 분할하세요.\n","\n","from sklearn.model_selection import train_test_split\n","from glob import glob\n","import shutil\n","import os\n","\n","train_img_path = '/content/Dataset/images/train/'\n","train_lab_path = '/content/Dataset/labels/train/'\n","val_img_path = '/content/Dataset/images/val/'\n","val_lab_path = '/content/Dataset/labels/val/'\n","\n","# 이미지와 라벨 파일 리스트로 가져오기\n","image_files = os.listdir(train_img_path)\n","label_files = os.listdir(train_lab_path)\n","\n","train_img, val_img, train_lab, val_lab = train_test_split(image_files, label_files, test_size=0.2, random_state=2023)\n","\n","for img_file in train_img:\n","    shutil.move(os.path.join(train_img_path, img_file), os.path.join(val_img_path, img_file))\n","for lab_file in train_lab:\n","    shutil.move(os.path.join(train_lab_path, lab_file), os.path.join(val_lab_path, lab_file))"],"metadata":{"id":"X37r7anMg1sv","executionInfo":{"status":"ok","timestamp":1695565306984,"user_tz":-540,"elapsed":2768,"user":{"displayName":"현수","userId":"15599720930867665035"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# 크기 출력\n","print(len(train_img))\n","print(len(val_img))\n","print(len(train_lab))\n","print(len(val_lab))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p0E9pd9gsF8s","executionInfo":{"status":"ok","timestamp":1695565306985,"user_tz":-540,"elapsed":5,"user":{"displayName":"현수","userId":"15599720930867665035"}},"outputId":"eece88ff-4566-4863-a7e7-fabae3f6c6a3"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["4174\n","1044\n","4174\n","1044\n"]}]},{"cell_type":"markdown","source":["### (2) json에서 정보 추출\n","---\n","- **세부요구사항**\n","    - json 파일에서 필요한 정보를 추출하세요:\n","        - 위치 정보 : x1, x2, y1, y2\n","        - 박스 정보 : shape_type\n","        - 클래스 정보 : labels\n","    - 화폐당 하나의 클래스로 변경하세요.\n","        - json 파일에는 화폐 클래스가 앞뒷면으로 구분되어 있습니다.\n","        - 화폐의 앞뒷면 구분을 없애주세요.\n","            - 예시 : 'ten_front', 'ten_back' -> 'ten'\n","    - 화폐의 위치 정보를 YOLO 모델 형식에 맞게 변경 해주세요.\n","        - 사용되는 이미지는 원본에서 1/5로 축소되어 있습니다.\n","        - json 파일의 정보는 원본 기준 데이터이므로 위치 정보 추출을 할 때 x값과 y값을 1/5로 줄여주세요.\n","    - 이렇게 변경된 정보를 YOLO label 형식에 맞게 txt파일로 저장 해 주세요.\n","        - Hint : YOLO Labeling Format [label, x-center, y-center, width-norm, height-norm]\n","---"],"metadata":{"id":"II_hsJ6bKYGn"}},{"cell_type":"code","source":["import os, json, glob"],"metadata":{"id":"MgUoCewjM-Jf","executionInfo":{"status":"ok","timestamp":1695565335396,"user_tz":-540,"elapsed":3,"user":{"displayName":"현수","userId":"15599720930867665035"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["json_path = '/content/Dataset/labels/'\n","temp_list = ['train', 'val']\n","\n","coin = {'Ten' : 0,\n","        'Fifty' : 1,\n","        'Hundred' : 2,\n","        'Five_Hundred' : 3,\n","        'Thousand' : 4,\n","        'Five_Thousand' : 5,\n","        'Ten_Thousand' : 6,\n","        'Fifty_Thousand' : 7}"],"metadata":{"id":"gBD1Zv9BKaxi","executionInfo":{"status":"ok","timestamp":1695565335812,"user_tz":-540,"elapsed":2,"user":{"displayName":"현수","userId":"15599720930867665035"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["labels_train_jsons = glob.glob('/content/Dataset/labels/train/*.json')\n","labels_val_jsons = glob.glob('/content/Dataset/labels/val/*.json')"],"metadata":{"id":"HqZETm45San_","executionInfo":{"status":"ok","timestamp":1695565336175,"user_tz":-540,"elapsed":2,"user":{"displayName":"현수","userId":"15599720930867665035"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":[" ########################\n","# 이 셀부터 코드 작성하세요\n","# Json 파일에서 필요한 정보만 골라 txt로 바꾸는 작업임을 기억하세요!\n","########################\n","\n","def change_to_txt(json_file, idx):\n","    if idx==0:\n","        cate='train'\n","    else:\n","        cate='val'\n","    for cur in json_file:\n","        data = json.load(open(cur))\n","        shapes = data['shapes']\n","        points = shapes[0]['points']\n","        label = shapes[0]['label']\n","        shape = shapes[0]['shape_type']\n","        x1, y1 = points[0]\n","        x2, y2 = points[1]\n","        image_width = data[\"imageWidth\"]\n","        image_height = data[\"imageHeight\"]\n","\n","        #label에서 앞, 뒤 제거\n","        if label[-1]=='k':\n","            label = label[:len(label)-5]\n","        else:\n","            label = label[:len(label)-6]\n","\n","        #기존에서 1/4한 x, y 센터 찾기\n","        x1, x2, y1, y2 = x1/5, x2/5, y1/5, y2/5\n","        width = x2 - x1\n","        height = y2 - y1\n","        x_center = x1 + (width/2)\n","        y_center = y1 + (height/2)\n","\n","        #전체 이미지에서 0~1사이 값으로 만들기\n","        x_center = x_center / (image_width/5)\n","        y_center = y_center / (image_height/5)\n","        width = width / (image_width/5)\n","        height = height / (image_height/5)\n","\n","        #txt 파일로 만들어 저장\n","        txt_name = data[\"imagePath\"].split(\".\")[0] + \".txt\"\n","        f = open(f\"/content/Dataset/labels/{cate}/{txt_name}\", 'w')\n","        f.write(f'{coin[label]} {x_center} {y_center} {width} {height}')\n","        f.close()\n","\n","change_to_txt(labels_train_jsons, 0)\n","change_to_txt(labels_val_jsons, 1)"],"metadata":{"id":"Mzh2Y8doMEK1","executionInfo":{"status":"ok","timestamp":1695565337269,"user_tz":-540,"elapsed":345,"user":{"displayName":"현수","userId":"15599720930867665035"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tOQeEhApesWR"},"source":["### (3) 데이터셋 정보가 담긴 파일 생성\n","---\n","- **세부요구사항**\n","    - 파일 안에 있어야 할 정보는 아래와 같습니다.\n","        - 학습할 클래스 이름 정보\n","        - 학습할 클래스 수 정보\n","        - Training, Validation 데이터셋 위치 정보\n","---\n","- 가장 대중적으로 이용하는 라이브러리는 yaml 입니다.\n","    - [yaml document](https://pyyaml.org/wiki/PyYAMLDocumentation)\n","    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n","---"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"pu1iQfQolBhJ","executionInfo":{"status":"ok","timestamp":1695565339903,"user_tz":-540,"elapsed":3,"user":{"displayName":"현수","userId":"15599720930867665035"}}},"outputs":[],"source":["import yaml"]},{"cell_type":"code","source":["coin_dict = {0:'10', 1:'50', 2:'100', 3:'500', 4:'1000', 5:'5000', 6:'10000', 7:'50000'}"],"metadata":{"id":"t1_uOeXcSvv3","executionInfo":{"status":"ok","timestamp":1695565340500,"user_tz":-540,"elapsed":3,"user":{"displayName":"현수","userId":"15599720930867665035"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","execution_count":20,"metadata":{"id":"qvMQcHirmSnD","executionInfo":{"status":"ok","timestamp":1695565340867,"user_tz":-540,"elapsed":2,"user":{"displayName":"현수","userId":"15599720930867665035"}}},"outputs":[],"source":["########################\n","# 이 셀부터 코드 작성하세요\n","########################\n","names = list(coin_dict.values())\n","nc = len(names)\n","train_path = '/content/Dataset/images/train'\n","val_path = '/content/Dataset/images/val'\n","\n","dataset_info = {\n","    \"names\": names,\n","    \"nc\": nc,\n","    \"train\": train_path,\n","    \"val\": val_path,\n","}\n","\n","with open('/content/Dataset/coin.yaml', 'w') as f :\n","    yaml.dump(dataset_info, f, default_flow_style=False)"]},{"cell_type":"markdown","source":["## 3.모델링"],"metadata":{"id":"3btFvySXi2dt"}},{"cell_type":"markdown","metadata":{"id":"0pQ2gRbTYgLL"},"source":["### (1) 모델 라이브러리 설치\n","---"]},{"cell_type":"code","source":["!git clone https://github.com/ultralytics/yolov5  # clone\n","!pip install -r yolov5/requirements.txt  # install"],"metadata":{"id":"Biyr9AHkMyNf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ########################\n","# # 이 셀부터 코드 작성하세요\n","# ########################\n","# temp_str = 'setuptools<=64.0.2\\n'\n","\n","# f = open('/content/yolov5/requirements.txt', 'r')\n","# f_str = f.readlines()\n","# f.close()\n","\n","# f2 = open('/content/yolov5/requirements.txt', 'w')\n","\n","# for idx, val in enumerate(f_str) :\n","#     if 'setuptools' in val :\n","#         idx_v = idx\n","#         f_str.remove(val)\n","#         f_str.insert(idx_v, temp_str)\n","\n","# for val in f_str :\n","#     f2.write(val)\n","\n","# f2.close()"],"metadata":{"id":"0hn4rKkWXcZz","executionInfo":{"status":"ok","timestamp":1695565349883,"user_tz":-540,"elapsed":7,"user":{"displayName":"현수","userId":"15599720930867665035"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["!cd yolov5; pip install -r requirements.txt"],"metadata":{"id":"4bd5dhDOXjdA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### (2) 가중치 파일 다운로드\n","---\n","- **세부요구사항**\n","    - 모델 개발자가 제공하는 사전 학습 가중치 파일을 다운로드 하세요.\n","        - 해당 과정이 불필요하다면 넘어가셔도 됩니다!\n","---"],"metadata":{"id":"_mHMAspjR6Xp"}},{"cell_type":"code","source":["%cd /content/yolov5\n","!wget https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5x.pt"],"metadata":{"id":"sSVIqkMLDIOd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W8-5lC4mfbwT"},"source":["### (3) 학습 : train.py\n","---\n","- **세부요구사항**\n","    - UltraLytics YOLO v5에는 아래의 데이터가 필요합니다.\n","        - 데이터셋 정보가 담긴 yaml 파일\n","        - 사용하려는 모델 구조에 대한 yaml 파일\n","        - 사용하려는 모델의 가중치 파일\n","---"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"4AYFDMaVfmTK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695566629682,"user_tz":-540,"elapsed":1271708,"user":{"displayName":"현수","userId":"15599720930867665035"}},"outputId":"93f3c3b2-bdcb-44f3-e4b2-e1f856ddbaea"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov5\n","WARNING ⚠️ invalid check_version(3.1.37, ) requested, please check values.\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5n.pt, cfg=./models/yolov5n.yaml, data=/content/Dataset/coin.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=coin_yolov5n_results, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=5, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","WARNING ⚠️ invalid check_version(5.9.5, ) requested, please check values.\n","YOLOv5 🚀 v7.0-224-g6262c7f Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00<00:00, 39.9MB/s]\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n.pt to yolov5n.pt...\n","100% 3.87M/3.87M [00:00<00:00, 131MB/s]\n","\n","Overriding model.yaml nc=80 with nc=8\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      1760  models.common.Conv                      [3, 16, 6, 2, 2]              \n","  1                -1  1      4672  models.common.Conv                      [16, 32, 3, 2]                \n","  2                -1  1      4800  models.common.C3                        [32, 32, 1]                   \n","  3                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  4                -1  2     29184  models.common.C3                        [64, 64, 2]                   \n","  5                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  6                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n","  7                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  8                -1  1    296448  models.common.C3                        [256, 256, 1]                 \n","  9                -1  1    164608  models.common.SPPF                      [256, 256, 5]                 \n"," 10                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 14                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     22912  models.common.C3                        [128, 64, 1, False]           \n"," 18                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]                \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1     74496  models.common.C3                        [128, 128, 1, False]          \n"," 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 24      [17, 20, 23]  1     17589  models.yolo.Detect                      [8, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [64, 128, 256]]\n","YOLOv5n summary: 214 layers, 1774741 parameters, 1774741 gradients, 4.3 GFLOPs\n","\n","Transferred 342/349 items from yolov5n.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Dataset/labels/train... 179 images, 865 backgrounds, 0 corrupt: 100% 1044/1044 [00:00<00:00, 9386.05it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Dataset/labels/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Dataset/labels/val... 3309 images, 865 backgrounds, 0 corrupt: 100% 4174/4174 [00:01<00:00, 3404.06it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Dataset/labels/val.cache\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.94 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Plotting labels to runs/train/coin_yolov5n_results/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/train/coin_yolov5n_results\u001b[0m\n","Starting training for 100 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       0/99         2G    0.09257    0.02141    0.05686          2        640: 100% 66/66 [00:14<00:00,  4.54it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:27<00:00,  4.79it/s]\n","                   all       4174       3309    0.00163      0.494    0.00152   0.000392\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       1/99      3.01G    0.06172   0.008964    0.04901          1        640: 100% 66/66 [00:09<00:00,  7.04it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:24<00:00,  5.44it/s]\n","                   all       4174       3309    0.00445      0.907     0.0389     0.0125\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       2/99      3.01G    0.04961   0.006246    0.04543          1        640: 100% 66/66 [00:10<00:00,  6.50it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:22<00:00,  5.71it/s]\n","                   all       4174       3309     0.0079      0.769     0.0714     0.0275\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       3/99      3.01G    0.04614   0.005879    0.04367          0        640: 100% 66/66 [00:09<00:00,  7.06it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:23<00:00,  5.57it/s]\n","                   all       4174       3309     0.0303      0.707      0.109     0.0555\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       4/99      3.01G    0.04447   0.006033    0.04493          2        640: 100% 66/66 [00:09<00:00,  6.84it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:24<00:00,  5.43it/s]\n","                   all       4174       3309    0.00759      0.932      0.129     0.0609\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       5/99      3.01G    0.04071   0.005769    0.04054          2        640: 100% 66/66 [00:08<00:00,  7.44it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:24<00:00,  5.34it/s]\n","                   all       4174       3309     0.0272      0.903       0.13     0.0524\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       6/99      3.01G    0.03951   0.005519    0.04256          0        640: 100% 66/66 [00:09<00:00,  7.04it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:22<00:00,  5.95it/s]\n","                   all       4174       3309     0.0309      0.197      0.028     0.0152\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       7/99      3.01G    0.03965   0.005435     0.0404          0        640: 100% 66/66 [00:09<00:00,  7.13it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:24<00:00,  5.44it/s]\n","                   all       4174       3309     0.0157      0.749      0.119     0.0613\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       8/99      3.01G    0.03638   0.005802    0.03878          1        640: 100% 66/66 [00:09<00:00,  6.86it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:23<00:00,  5.62it/s]\n","                   all       4174       3309     0.0126      0.806      0.114     0.0579\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       9/99      3.01G    0.03873   0.005334    0.03723          0        640: 100% 66/66 [00:09<00:00,  6.88it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:24<00:00,  5.38it/s]\n","                   all       4174       3309     0.0185      0.876      0.153     0.0928\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      10/99      3.01G    0.03675   0.005279    0.03664          2        640: 100% 66/66 [00:09<00:00,  6.99it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:23<00:00,  5.51it/s]\n","                   all       4174       3309     0.0158      0.939      0.202       0.11\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      11/99      3.01G    0.03729   0.005381    0.03719          0        640: 100% 66/66 [00:09<00:00,  7.31it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:25<00:00,  5.21it/s]\n","                   all       4174       3309      0.654      0.206      0.266      0.171\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      12/99      3.01G    0.03279   0.005298    0.03528          0        640: 100% 66/66 [00:09<00:00,  6.83it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:24<00:00,  5.40it/s]\n","                   all       4174       3309     0.0191      0.944      0.256      0.145\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      13/99      3.01G    0.03453   0.005598    0.03616          1        640: 100% 66/66 [00:09<00:00,  6.81it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:24<00:00,  5.35it/s]\n","                   all       4174       3309      0.232      0.393      0.225      0.146\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      14/99      3.01G    0.03211   0.005542    0.03448          1        640: 100% 66/66 [00:09<00:00,  6.98it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:25<00:00,  5.22it/s]\n","                   all       4174       3309      0.803      0.214      0.305      0.194\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      15/99      3.01G    0.03179   0.004848    0.03432          2        640: 100% 66/66 [00:08<00:00,  7.40it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:24<00:00,  5.25it/s]\n","                   all       4174       3309      0.285      0.749      0.342      0.224\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      16/99      3.01G    0.03255    0.00532    0.03239          1        640: 100% 66/66 [00:10<00:00,  6.50it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:20<00:00,  6.28it/s]\n","                   all       4174       3309     0.0312      0.427     0.0868     0.0534\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      17/99      3.01G    0.03067   0.005076    0.03325          2        640: 100% 66/66 [00:09<00:00,  7.12it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:24<00:00,  5.32it/s]\n","                   all       4174       3309       0.18      0.809      0.263      0.179\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      18/99      3.01G    0.03226   0.005002     0.0319          1        640: 100% 66/66 [00:09<00:00,  6.72it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:24<00:00,  5.28it/s]\n","                   all       4174       3309      0.281      0.557      0.374      0.243\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      19/99      3.01G    0.02919   0.005073    0.02974          5        640: 100% 66/66 [00:09<00:00,  7.21it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:25<00:00,  5.22it/s]\n","                   all       4174       3309      0.392      0.365      0.308      0.196\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      20/99      3.01G     0.0304   0.005412    0.03057          1        640: 100% 66/66 [00:09<00:00,  7.18it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:25<00:00,  5.22it/s]\n","                   all       4174       3309      0.857      0.204      0.339      0.235\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      21/99      3.01G    0.02755   0.005358    0.02859          0        640: 100% 66/66 [00:09<00:00,  6.80it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:24<00:00,  5.29it/s]\n","                   all       4174       3309      0.835      0.314      0.405      0.249\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      22/99      3.01G    0.02859   0.005214    0.03083          3        640: 100% 66/66 [00:09<00:00,  6.64it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:24<00:00,  5.31it/s]\n","                   all       4174       3309      0.854        0.3      0.407      0.286\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      23/99      3.01G    0.02625   0.005165    0.03029          0        640: 100% 66/66 [00:08<00:00,  7.83it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:24<00:00,  5.40it/s]\n","                   all       4174       3309       0.89      0.297      0.399      0.289\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      24/99      3.01G    0.02685   0.004811    0.02827          0        640: 100% 66/66 [00:09<00:00,  7.00it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:23<00:00,  5.56it/s]\n","                   all       4174       3309      0.876      0.243      0.353       0.25\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      25/99      3.01G     0.0255   0.005089    0.02681          1        640: 100% 66/66 [00:10<00:00,  6.54it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:23<00:00,  5.46it/s]\n","                   all       4174       3309      0.821      0.238      0.381      0.286\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      26/99      3.01G    0.02375   0.004863    0.02588          1        640: 100% 66/66 [00:09<00:00,  6.82it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:23<00:00,  5.52it/s]\n","                   all       4174       3309      0.896      0.127      0.314      0.225\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      27/99      3.01G    0.02553   0.005165    0.02615          1        640: 100% 66/66 [00:08<00:00,  7.37it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:23<00:00,  5.50it/s]\n","                   all       4174       3309      0.681      0.151      0.266      0.189\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      28/99      3.01G     0.0294    0.00473     0.0265          0        640: 100% 66/66 [00:08<00:00,  7.53it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:24<00:00,  5.33it/s]\n","                   all       4174       3309      0.912      0.303      0.428      0.321\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      29/99      3.01G     0.0258     0.0048    0.02636          3        640: 100% 66/66 [00:09<00:00,  7.13it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:23<00:00,  5.47it/s]\n","                   all       4174       3309      0.848      0.342      0.459      0.346\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      30/99      3.01G    0.02668    0.00503     0.0273          1        640: 100% 66/66 [00:09<00:00,  6.98it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:24<00:00,  5.29it/s]\n","                   all       4174       3309      0.753      0.285      0.417      0.311\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      31/99      3.01G    0.02638   0.004854    0.02283          1        640: 100% 66/66 [00:09<00:00,  6.83it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:24<00:00,  5.28it/s]\n","                   all       4174       3309      0.464      0.307      0.397      0.306\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      32/99      3.01G    0.02654   0.004877    0.02788          3        640: 100% 66/66 [00:09<00:00,  7.21it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:24<00:00,  5.39it/s]\n","                   all       4174       3309      0.563      0.288      0.394      0.308\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      33/99      3.01G    0.02209    0.00489     0.0235          0        640: 100% 66/66 [00:09<00:00,  7.22it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:23<00:00,  5.50it/s]\n","                   all       4174       3309      0.772      0.276      0.397      0.312\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      34/99      3.01G    0.02373   0.004829    0.02621          2        640: 100% 66/66 [00:09<00:00,  6.72it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:24<00:00,  5.39it/s]\n","                   all       4174       3309       0.49      0.288       0.42      0.312\n","Stopping training early as no improvement observed in last 5 epochs. Best results observed at epoch 29, best model saved as best.pt.\n","To update EarlyStopping(patience=5) pass a new patience value, i.e. `python train.py --patience 300` or use `--patience 0` to disable EarlyStopping.\n","\n","35 epochs completed in 0.334 hours.\n","Optimizer stripped from runs/train/coin_yolov5n_results/weights/last.pt, 3.8MB\n","Optimizer stripped from runs/train/coin_yolov5n_results/weights/best.pt, 3.8MB\n","\n","Validating runs/train/coin_yolov5n_results/weights/best.pt...\n","Fusing layers... \n","YOLOv5n summary: 157 layers, 1769989 parameters, 0 gradients, 4.2 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 131/131 [00:24<00:00,  5.25it/s]\n","                   all       4174       3309      0.848      0.342      0.458      0.346\n","                    10       4174        288          1          0      0.228      0.157\n","                    50       4174        284          1          0      0.207      0.158\n","                   100       4174        268          1          0        0.2      0.136\n","                   500       4174        285          1          0      0.256      0.212\n","                  1000       4174        546      0.767      0.826      0.779      0.563\n","                  5000       4174        515      0.659      0.961      0.727      0.546\n","                 10000       4174        578      0.598      0.913      0.654      0.521\n","                 50000       4174        545      0.763     0.0385      0.617      0.475\n","Results saved to \u001b[1mruns/train/coin_yolov5n_results\u001b[0m\n"]}],"source":["# train.py\n","%cd /content/yolov5\n","!python train.py --img 640 --batch 16 --epochs 100 --patience 5 --data /content/Dataset/coin.yaml --cfg ./models/yolov5n.yaml --weights yolov5n.pt --name coin_yolov5n_results"]},{"cell_type":"markdown","metadata":{"id":"u2YESAa5fc4M"},"source":["\n","## 4.탐지 : detect.py\n","---\n","- **세부요구사항**\n","    - 학습 과정에서 생성된 가중치 파일을 이용하세요.\n","    - IoU threshold를 0.25 이하로 설정하세요.\n","    - confidence threshold를 0.75 이상으로 설정하세요.\n","---\n","- 여러분이 **직접 촬영한 화폐 사진과 동영상**을 탐지 과정에 이용하여 결과를 확인하세요.\n","    - 조건\n","        1. 화폐의 수를 늘려가며 촬영 해보세요.\n","            - ex) 50원 하나, 50원 둘, 50원 셋, ...\n","        2. 화폐의 종류를 늘려가며 촬영 해보세요.\n","            - ex) 50원 하나와 100원 하나, 50원 하나와 100원 하나와 1000원 하나, ...\n","        3. 사진은 최소 30장 이상, 동영상은 최소 하나 이상 촬영하여 사용 해보세요.\n","---"]},{"cell_type":"code","source":["########################\n","# 이 셀부터 코드 작성하세요\n","########################\n"],"metadata":{"id":"9rK0ClfTcjEZ","executionInfo":{"status":"ok","timestamp":1695566629683,"user_tz":-540,"elapsed":6,"user":{"displayName":"현수","userId":"15599720930867665035"}}},"execution_count":26,"outputs":[]}]}